---
title: "CW3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #includes dplyr, ggplot2, stringr
library(GGally)
library(car)
library(ggpubr)
library(gridExtra)
library(kableExtra)
library(lmtest)
library(MASS)
library(arm) #used for binnedplot
library(boot) #used for cross-validation function

data <- read.csv("AirnbnbRio.csv")

old <- theme_set(theme_bw()) #set ggplot theme throughout doc
```

## Cleaning data

```{r}
#Converting character variables to factor variables
data$host_response_rate <- as.factor(data$host_response_rate)
data$neighbourhood <- as.factor(data$neighbourhood)
data$property_type <- as.factor(data$property_type)
data$room_type <- as.factor(data$room_type)

#Converting "N/A" in host response rate into recognised missing values
data$host_response_rate <- na_if(data$host_response_rate,"N/A")

#Reformatting host_response_rate to a numerical variable and removing "%" sign
levels(data$host_response_rate) <- str_replace_all(levels(data$host_response_rate), "%", "")
data$host_response_rate <- as.numeric(data$host_response_rate)

#Converting all of the integer variables to numerical variables
data <- data %>% mutate(across(.cols=where(is.integer), .fns=as.numeric))

#Changing column names
colnames(data)<-c("price","resp_rate","list_count","n_hood","prop_type","room_type", "bathrooms", "accommodates", "guests", "min_nights", "num_reviews", "revs_month", "revs_rating", "avail_30")

summary(data)
```
Investigating variables and outliers:
```{r}
data %>% filter(min_nights>50) %>% arrange(desc(min_nights))
# airbnb founded in 2008 so hosts can only have had properties listed for max 10 years by April 2018
# min length of stay:
## 1000 days: 99 reviews but only 2 guests per stay so would take over 100 years to accummulate this many reviews -> suggests some sort of error/contradiction
## 365 days: 65 reviews, 4 guests per stay => 4 reviews per year, >16 years to accummulate 67 reviews

#Removing contradictory outliers for min_nights
data <- subset(data, min_nights<365)

#New variable diff: difference between accommodates and guests
diff <- data$accommodates - data$guests
summary(diff)
sum((diff < 0))
# 48 properties where guests included in price is larger than accommodates
# should always have guests > accommodates

#Removing the 48 observations where guests > accommodates 
data <- data %>% filter(data$guests <= data$accommodates)
```
## Investigating missingness

```{r}
#Proportion of missingness in data set for each variable
apply(is.na(data),2,mean)
#the proportion of complete cases
mean(apply(is.na(data),1,sum)==0)

#Distribution of missing values
source("plot.miss.R")
plot.miss(data, c(2,3,7,12,13))
#Looks random
```

Missingness in host response rate:
```{r}
#Correlation between missingness in host response rate and other variables
resp_miss <-is.na(data$resp_rate)
cor(data[,-c(2,4,5,6)],resp_miss,use= "pairwise")

#Relationship with reviews and listings:
grid.arrange(
ggplot(aes(x=resp_miss,y=num_reviews),data=data) + geom_boxplot() + coord_flip(),
ggplot(aes(x=resp_miss,y=revs_month),data=data) + geom_boxplot() + coord_flip()
)
data %>% filter(list_count<100) %>%
  ggplot(aes(x=is.na(resp_rate),y=list_count)) + geom_boxplot() + coord_flip()

par(mfrow=c(1,2))
bins_revs <- quantile( data$num_reviews, prob = (0:10)/10 )
bins_revs_miss <- rep( 0, 10 )
for( i in 1:10 )
  bins_revs_miss[i] <- sum( resp_miss[data$num_reviews>=bins_revs[i] &
                                      data$num_reviews<bins_revs[i+1]] )
plot(x=bins_revs[1:10],y=bins_revs_miss,xlab="Number of reviews",
     ylab="Missing response rate values",pch=20)

bins_revs2 <- quantile( data$revs_month, prob = (0:10)/10, na.rm=T )
bins_revs_miss2 <- rep( 0, 10 )
for( i in 1:10 )
  bins_revs_miss2[i] <- sum( resp_miss[na.omit(data$revs_month)>=bins_revs2[i] &
                                       na.omit(data$revs_month)<bins_revs2[i+1]] )
plot(x=bins_revs2[1:10],y=bins_revs_miss2,xlab="Reviews per month",
     ylab="Missing response rate values",pch=20)

#Relationship with factor variables:
round(prop.table(xtabs(~ resp_miss + n_hood, data),2),2)
round(prop.table(xtabs(~ resp_miss + room_type, data),2),2)
round(prop.table(xtabs(~ resp_miss + prop_type, data),2),2)

# missingness of host response rate seems to depend on frequency/number of reviews and number of listings a host has
# also varies across neighbourhood and type of property
# most likely MAR
```
Summary of missing data:

* Missing values in 5 variables: number of property listings, host response rate, number of bathrooms, reviews per month and property rating
* 88.0% of total observations are complete
* Host response rate has 11.7% data missing, while the other variables have less than 0.5% missing
* Missingness in host response rate depends on frequency of reviews, number of listings, location and type of property, so is likely to be MAR instead of MCAR
* Tiny proportions in other variables means missing values can be omitted without analysis being affected


## Exploratory data analysis

Correlations between variables:
```{r}
#Correlation matrix
cvars<-c(colnames(data)[-c(4,5,6)])
noNAs <- na.omit(data[,-c(4,5,6)]) 
cors <- round(cor(noNAs, use = "pairwise"),2)
#cors

as.data.frame(cors)%>%
  mutate_all(~cell_spec(.x, color = ifelse(abs(.x)>=0.3, "red"," black"))) %>%
  kable(escape = F) %>%
  kable_styling(font_size = 7)
```
Reading from the table tells us which explanatory variables have high correlation and have the potential to be removed from our models later on if a highly correlated variable already exists and which variables to expect to be in final models. 

We do not want multicollinearity affecting our model and resulting in less accurate statistical inferences.
High correlations are as follows:

* Price: bathrooms(0.56), accommodates(0.52), guests(0.30)
* Bathrooms: accommodates(0.59), guests(0.35)
* Accommodates: guests(0.49)
* Number of reviews: reviews per month(0.55)

(Should only use one variable out of number of reviews and reviews per month as they measure the same thing, and are correlated.)

Response rate, host listing counts, review rating and 30 day availability appear to not be strongly correlated with any of the other factors.

```{r}
#Histograms and boxplots of variables
par(mfrow = c(3,5))
for(v in cvars[])hist(data[,v], xlab =v, main = c("Histogram of", v))
barplot(xtabs(~data$n_hood),las=1, main = c("Barplot of ","Neighbourhood"))
barplot(xtabs(~data$prop_type),las= 1,main = c("Barplot of ","Property Type"))
barplot(xtabs(~data$room_type),las= 1,main = c("Barplot of ","Room Type"))
```
We see that all variables are right-skewed except for revs_rating and avail_30 which are left-skewed (and neighbourhood which looks normally distributed).

Discussing histograms & distributions of data:

* Price: right-skewed
* Response Rate: majority are close to 0 
* Listings count: majority are close to 0
* Neighbourhood: majority in Copacabana
* Property type: most are apartments
* Room type: most are entire home
* Bathrooms: right skewed
* Accomodates:right skewed
* Guests: right-skewed
* Min nights: right-skewed with some large values (300,365,1000)
* Num of reviews: right-skewed many values with only 1 observation, might require some grouping for those
* Revs per month: right-skewed
* Revs rating: left-skewed
* Available 30: somewhat uniform in middle with very large tails

```{r}
#Also checking for skew with density plots
par(mfrow = c(3,5))
for(v in cvars[])densityPlot(data[,v], xlab =v, main = c("Density of", v))
```

```{r, echo=FALSE}
#Investigating outliers with boxplots
par(mfrow = c(3,4))
for(v in cvars[])boxplot(data[,v], main = v, las = 2)
#resp_rate, list_count, bathrooms, accommodates, guests, revs_month, revs_rating and avail_30
```


# Question 1: Factors affecting price

Plotting our variables against price gives us an idea of any problems (outliers, unrealistic values etc.) or features of the data that we didn't detect in our summaries.

```{r, echo=FALSE}
#Continuous variables
par(mfrow=c(3,4))
for(v in cvars[-1])plot(data[,v], data$price, xlab =v, ylab="Price")
```

```{r}
#Factors
plot2 <- grid.arrange(ggplot(data,aes(price,n_hood))+geom_boxplot()+
               labs(x="Daily price",y="Neighbourhood"),
             ggplot(data,aes(price,prop_type))+geom_boxplot()+
               labs(x="Daily price",y="Property"),
             ggplot(data,aes(price,room_type))+geom_boxplot()+
               labs(x="Daily price",y="Room type"),
             ncol=2)
```

```{r}
plot(density(data$price))
ggqqplot(data$price)
#Log transform
ggqqplot(log(data$price))
```

So price qqplot is a crazy shape but log(price) seems to have almost normal distribution. May come in useful!
Price looks almost like a gamma distribution
```{r}
#Variables that have correlation larger than 0.25 with price
which(cors[,1]>0.25)
```

```{r}
#Full linear model with reviews per month
full_lm1 <- lm(price ~. -num_reviews, data = na.omit(data))
#Full linear model with number of reviews
full_lm2 <- lm(price ~. -revs_month, data = na.omit(data))

#Full linear model with accommodates and reviews per month - gives best AIC
full_lm3 <- update(full_lm1, .~. -guests)
#Full linear model with guests and reviews per month
full_lm4 <- update(full_lm1, .~. -accommodates)
AIC(full_lm3)
AIC(full_lm4)

#No better when trying accommodates/guests with number of reviews.

#Finding "best" linear model by comparing AIC using 'step' function 
#with reviews per month
best_lm1 <- step(full_lm3, trace = F)
AIC(best_lm1)

#Diagnostic plots
par(mfrow=c(2,2))
plot(best_lm1)

#Box-Cox transformation plot
boxcox(best_lm1, lambda=seq(0,0.1,0.01))
#95% CI for lambda includes 0, so log transformation suitable

#Model with log transform of response variable.
log_best_lm <- update(best_lm1, log(.)~.)
AIC(log_best_lm)

#Using step to find best linear model by comparing AIC
best_lm <- step(log_best_lm, trace = F)
summary(best_lm)
AIC(best_lm)
#Diagnostic plots
par(mfrow=c(2,2))
plot(best_lm)
```
We see that only some variables are statistically significant in predicting price, namely: list_count, neighbourhood, property type, room type, bathrooms, accommodates, guests, revs_month, revs_rating and avail_30.

Final linear model gave AIC = 4084, but only has r-squared = 54%.

```{r}
#Q-Q plots of linear and log linear 
par(mfrow = c(1,2))
plot(best_lm1,2)
plot(best_lm,2)
```

```{r}
#Trying a Gamma distribution first because that's what price's density plot looked like.

#Full Gamma model with reviews per month
gam_mod1 <- glm(price ~. - num_reviews, family = Gamma(link = "log"), data = na.omit(data))
AIC(gam_mod1)

#Full Gamma model with number of reviews
gam_mod2 <- glm(price ~. - revs_month, family = Gamma(link = "log"), data = data)
AIC(gam_mod2)

#with accommodates - lower AIC
gam_mod3 <- update(gam_mod1, .~. -guests)
AIC(gam_mod3)
summary(gam_mod3)
#with guests
gam_mod4 <- update(gam_mod1, .~. -accommodates)
AIC(gam_mod4)
summary(gam_mod4)

#Step to find best gamma model
best_gam_mod <- step(gam_mod3, trace = F)
AIC(best_gam_mod)
#Diagnostic plots
par(mfrow = c(2,2))
plot(best_gam_mod)

#Gamma model with log transform on price
### (won't link function already log price? so would this log it twice? -V)
best_log_gam_mod <- update(best_gam_mod, log(.)~.)
summary(best_log_gam_mod)
AIC(best_log_gam_mod)
#Diagnostic plots
par(mfrow=c(2,2))
plot(best_log_gam_mod)

#Tests
qchisq(df=4016,p=0.05, lower.tail=FALSE)
bptest(best_log_gam_mod)

#Testing with identity link function
test <- update(best_log_gam_mod, family = Gamma(link = "identity"))
#Gives larger AIC compared to log link function
AIC(test)
```
Gamma distribution gave good fit with log transform of price, diagnostic plots looked good. Final gamma model had AIC = 4080, which is lower than the linear model.

```{r}
#Gaussian glm model

#Full Gaussian model with reviews per month
gau_mod1 <- glm(price ~. - num_reviews, family = gaussian(link = "log"), data = na.omit(data))
AIC(gau_mod1)

#Full Gaussian model with number of reviews
gau_mod2 <- glm(price ~. - revs_month, family = gaussian(link = "log"), data = data)
AIC(gau_mod2)

#Using step to find best Gaussian model
best_gau_mod <- step(gau_mod1, trace = F)
AIC(best_gau_mod)
#Diagnostic plots
par(mfrow = c(2,2))
plot(best_gau_mod)

#Log transform on price
best_log_gau_mod <- update(best_gau_mod, log(.)~.)
summary(best_log_gau_mod)
AIC(best_log_gau_mod)
#Diagnostic plots
par(mfrow = c(2,2))
plot(best_log_gau_mod)

cbind(exp(coef(best_log_gau_mod))-1)

#Testing with inverse link function
test <- update(best_log_gau_mod, family = gaussian(link = "inverse"))
AIC(test)
#Gives larger AIC
```
Gaussian model with log transform on price gives AIC = 4072, diagnostic plots also look good.

We tried inverse gaussian, model wasn't as good. Normally for highly right skewed.
```{r}
#Inverse Gaussian models, may be more suited as variables are highly right skewed
inv_gau_mod1 <- glm(price ~. - num_reviews, family = inverse.gaussian(link = "log"), data = na.omit(data))
summary(inv_gau_mod1)
par(mfrow = c(2,2))
plot(inv_gau_mod1)

log_inv_gau_mod1 <- update(inv_gau_mod1, log(.)~.)
summary(log_inv_gau_mod1)
par(mfrow = c(2,2))
plot(log_inv_gau_mod1)
```

```{r}
#Looking at the different diagnostic plots from all models
par(mfrow = c(2,2))
plot(best_lm)
par(mfrow = c(2,2))
plot(best_log_gam_mod)
par(mfrow = c(2,2))
plot(best_log_gau_mod)

par(mfrow = c(2,2))
plot(predict(best_log_gam_mod),resid(best_log_gam_mod),pch=20,
     xlab="Linear predictor",ylab="Deviance residuals")
plot(predict(best_log_gau_mod),resid(best_log_gau_mod),pch=20,
     xlab="Linear predictor",ylab="Deviance residuals")
qqnorm(resid(best_log_gam_mod))
qqnorm(resid(best_log_gau_mod))
```
Linear and Gaussian model has better diagnostic plots compared to gamma. Gaussian model and log linear mode have very similar diagnostic plots.

We choose the log linear model!
```{r}
summary(best_lm)
```
We see all variables are significant.

```{r}
#Confidence Intervals and coefficients table
table <- data.frame(cbind((exp(coef(best_lm)[-1])-1)*100,exp(confint(best_lm)[-1,])))
table
```


# Question 2: Predicting availability for the next 30 days

Initial thoughts / stuff for report:

* Want to predict whether or not there is availability within the next 30 days based on the variables provided - binary variable can be used as response
* Other variables that might be important to know: 
  + Host availability in next 30 days
  + Amount of advanced notice required between booking and staying
  + Season/time of year, e.g. during carnival or not (but might only be needed if we wanted to generalise prediction rather as data is taken from one point in time)
* Consider prediction error and cross-validation
* Misclassification rates suitable for binary/categorical responses to measure accuracy of prediction
* Since we are interested in prediction, don't want to remove variables purely on the basis that they aren't significant. But also don't want to overfit the model.

```{r}
#Create new variable for whether or not there is at least 1 day available in next month
data %>% mutate(avail = factor(ifelse(avail_30 < 1, 0, 1))) -> data
summary(data$avail)

#Proportion of listings that have availability
tab <- table(data$avail)
tab[2]/sum(tab)
# 85.18%
# much higher proportion have at least 1 day available compared to none (not surprising as not many properties are likely to be fully booked), which may affect the fit/performance of models
```

```{r}
par(mfrow=c(3,5))
for(v in cvars[-11]) boxplot(data[,v],data$avail, ylab =v, main = c("Availability and", v))
```

```{r}
# Exploratory data analysis
# Factors:
round(prop.table(xtabs( ~ avail + n_hood, data ),2),2)
round(prop.table(xtabs( ~ avail + prop_type, data ),2),2)
round(prop.table(xtabs( ~ avail + room_type, data ),2),2)
  # type of property seems to affect availability
```

```{r,echo=F}
# Continuous variables:
par(mfrow=c(2,2))
price_avail <- xtabs( ~ avail + price, data )
prob_price  <- price_avail[2,] / ( price_avail[1,] + price_avail[2,])
plot( sort( unique( data$price ) ), prob_price, pch=19,
      xlab="Daily price", ylab="Probability of being available")

resp_avail <- xtabs( ~ avail + resp_rate, data )
prob_resp  <- resp_avail[2,] / ( resp_avail[1,] + resp_avail[2,])
plot( sort( unique( data$resp_rate ) ), prob_resp, pch=19,
      xlab="Host response rate", ylab="Probability of being available")

list_avail <- xtabs( ~ avail + list_count, data )
prob_list  <- list_avail[2,] / ( list_avail[1,] + list_avail[2,])
plot( sort( unique( data$list_count ) ), prob_list, pch=19,
      xlab="Number of listings", ylab="Probability of being available")

bath_avail <- xtabs( ~ avail + bathrooms, data )
prob_bath  <- bath_avail[2,] / ( bath_avail[1,] + bath_avail[2,])
plot( sort( unique( data$bathrooms ) ), prob_bath, pch=19,
      xlab="# bathrooms", ylab="Probability of being available")

accomm_avail <- xtabs( ~ avail + accommodates, data )
prob_accomm  <- accomm_avail[2,] / ( accomm_avail[1,] + accomm_avail[2,])
plot( sort( unique( data$accommodates ) ), prob_accomm, pch=19,
      xlab="People property can accommodate", ylab="Probability of being available")

guest_avail <- xtabs( ~ avail + guests, data )
prob_guest  <- guest_avail[2,] / ( guest_avail[1,] + guest_avail[2,])
plot( sort( unique( data$guests ) ), prob_guest, pch=19,
      xlab="Number of guests", ylab="Probability of being available")

min_avail <- xtabs( ~ avail + min_nights, data )
prob_min  <- min_avail[2,] / ( min_avail[1,] + min_avail[2,])
plot( sort( unique( data$min_nights ) ), prob_min, pch=19,
      xlab="Min length of stay", ylab="Probability of being available")

revs_avail <- xtabs( ~ avail + revs_month, data )
prob_revs  <- revs_avail[2,] / ( revs_avail[1,] + revs_avail[2,])
plot( sort( unique( data$revs_month ) ), prob_revs, pch=19,
      xlab="Reviews per month", ylab="Probability of being available")
```

```{r}
data2 <- na.omit(data)

# Create test and training datasets
set.seed(1804)
n=dim(data2)[1]
i=sample(1:n,0.2*n)

test=data2[i,] #20% of dataset
train=data2[-i,] #80% of dataset
```

Omitted variables: num_reviews (highly correlated with revs_month), accommodates (highly correlated with guests). Might also be appropriate to exclude number of listings as it shouldn't really help predict availability of individual properties (but have kept it in for now)

```{r}
#Response variable is binary so use GLM with binomial EF and logit link
#Build model for prediction using training data

#(Almost) Full model
full_train <- glm(avail ~ price + resp_rate + n_hood + prop_type + 
                room_type + guests + bathrooms + min_nights + revs_month + 
                revs_rating, family=binomial(link="logit"), data=train)
summary(full_train)
# based on context, list count and bathrooms shouldn't affect property being available

#Small model chosen for lowest AIC (for comparison)
step_train <- step(full_train, trace = FALSE)
summary(step_train)
```

Most variables are associated with a higher odds of availability (though not many are significant). For example, a property costing $50 more than an otherwise identical one is 6.5% more likely to have availability in the next month. However, a higher rating and longer minimum stay are associated with a lower likelihood of a property being available. These relationships are what we would expect in the context. While only price, minimum stay and monthly reviews are significant at the 5% level, the other variables still seem important for predictive purposes and so will be kept in the model.

Diagnostics:
```{r}
#Fitted values vs residuals
binnedplot( full_train$fitted.values, residuals(full_train, type="deviance"),
            nclass = 15, ylab="Average deviance residuals" )
binnedplot( step_train$fitted.values, residuals(step_train, type="deviance"),
            nclass = 15, ylab="Average deviance residuals" )

#Continuous predicts vs residuals for full_train
par(mfrow=c(2,3))
binnedplot( train$price, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Daily price" )
binnedplot( na.omit(train)$resp_rate, residuals(full_train, type="deviance"),
            nclass = 10, xlab="Response rate" )
binnedplot( train$guests, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Number of guests" )
binnedplot( train$bathrooms, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Number of bathrooms" )
binnedplot( train$min_nights, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Minimum length of stay" )
binnedplot( train$revs_month, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Reviews per month" )
binnedplot( train$revs_rating, residuals(full_train, type="deviance"),
            nclass = 15, xlab="Rating" )
# fit doesn't look that good
# residuals seems to be distributed around 0.2 instead of 0
```

```{r}
#Continuous variables vs linear predictor
tmp <- train %>% dplyr::select_if(is.numeric) 
predictors <- colnames(tmp)
probs <- predict(step_train, type = "response")
tmp <- tmp %>%
  mutate(logit = log(probs/(1-probs))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)
ggplot(tmp, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  facet_wrap(~predictors, scales = "free_y")

tmp_step <- train %>% dplyr::select(price,min_nights,revs_month)
predictors_step <- c("price","min_nights","revs_month")
probs_step <- predict(step_train, type = "response")
tmp_step <- tmp_step %>%
  mutate(logit = log(probs_step/(1-probs_step))) %>%
  gather(key = "predictors_step", value = "predictor.value", -logit)
ggplot(tmp_step, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  facet_wrap(~predictors_step, scales = "free_y")

# vertical lines could mean predictor doesn't really affect logit response
```

```{r}
## Define the bins
num_bins <- 20
cut_offs <- quantile( full_train$fitted.values, 
                      (0:num_bins) / num_bins )

## Store availability status as numeric 0 or 1
avail_numeric <- as.numeric(train$avail)-1

## Compute observed and predicted proportions for each bin
proportion_observed  <- rep(0, num_bins)
proportion_predicted <- rep(0, num_bins) 

for( i in 1:num_bins ){
  ind <- which( full_train$fitted.values >= cut_offs[i] & 
                full_train$fitted.values <  cut_offs[i+1]  )
  proportion_observed[i]  <- mean( avail_numeric[ind] )
  proportion_predicted[i] <- mean( full_train$fitted.values[ind] )
}

## Plot predicted against observed proportions
plot( proportion_predicted, proportion_observed, pch=20,
      xlab="Predicted Proportions", ylab="Observed Proportions",
      main="Plot of fitted vs observed probabilities of being available",
      xlim=c(0.7,1),ylim=c(0.7,1))
abline(0,1,lty=2)

# fit doesn't look too bad
```


Prediction accuracy in training data:
```{r}
#Brier score:
brier.score=function(y,model) {
    pred.prob=predict(model,type="response") #predicted probabilities
    mean((pred.prob - y)^2)
}

brier.score(as.numeric(train$avail)-1,full_train)
brier.score(as.numeric(train$avail)-1,step_train)

#Function to calculate misclassification rate
mis.class=function(observed,y,model,p) {
    pred=predict(model,observed,type="response") #probability predicted by model
    xx=xtabs(~y+(pred>p))
    mc_rate=(xx[1,2]+xx[2,1])/(sum(xx)) #proportion that are correctly predicted
    
    #sensitivity & specificity
    se=xx[2,2]/sum(xx[2,])
    sp=xx[1,1]/sum(xx[1,])
    
    round(cbind(mc_rate,se,sp),4)
}

mis.class(train,train$avail,full_train,0.5)
mis.class(train,train$avail,step_train,0.5)
```


```{r}
#Misclassification rate when cut-off probability is taken to be 0
predicted1 <- as.integer(full_train$fitted.values < 1)
(tbl <- table(predicted1,train$avail))
mean(predicted1 != train$avail) #11.75% correctly predicted because of imbalance in data

predicted2 <- as.integer(step_train$fitted.values < 1)
(tbl2 <- table(predicted2,train$avail))
mean(predicted2 != train$avail)

#sensitivity = true positive rate
#specificity = true negative rate
```

Prediction error in test data:
```{r}
pred=predict(full_train,test,type="response")
xtabs(~test$avail+(pred>0.5))

mis.class(test,test$avail,full_train,0.5)
mis.class(test,test$avail,step_train,0.5)

# very low specificity => very high false positive rate (availability when there isn't)
# fully booked listings are not predicted well

#Try increasing cut-off probability:
#ROC curve to determine trade-off between sensitivity & specificity
threshold <- seq(0.8,0.9,0.01)
se=rep(0,10); sp=rep(0,10)
for(i in 1:10){
  predicted <- as.integer(predict(full_train,test,type="response") > threshold[i])
  xx=xtabs(~test$avail+predicted)
  se[i]=xx[2,2]/sum(xx[2,])
  sp[i]=xx[1,1]/sum(xx[1,])
}
plot(x=1-sp,y=se,pch=20,)
lines(1-sp, se)
text(1-sp, se, labels=threshold, cex=0.7, pos=3) #take p=0.86

threshold <- seq(0.8,0.9,0.01)
se=rep(0,10); sp=rep(0,10)
for(i in 1:10){
  predicted <- as.integer(predict(step_train,test,type="response") > threshold[i])
  xx=xtabs(~test$avail+predicted)
  se[i]=xx[2,2]/sum(xx[2,])
  sp[i]=xx[1,1]/sum(xx[1,])
}
plot(x=1-sp,y=se,pch=20,)
lines(1-sp, se)
text(1-sp, se, labels=threshold, cex=0.7, pos=3) #take p=0.87

#New rates
mis.class(test,test$avail,full_train,0.87)
mis.class(test,test$avail,step_train,0.87)

#Misclassification rates when model always predicts that there is availability
predicted1 <- as.integer(predict(full_train,test,type="response") < 1)
(tbl2 <- table(predicted1,test$avail))
mean(predicted1 != test$avail)

predicted2 <- as.integer(predict(step_train,test,type="response") < 1)
(tbl2 <- table(predicted2,test$avail))
mean(predicted2 != test$avail)
```


# Question 3: Factors associated with very high review ratings

```{r}
summary(data$revs_rating)
#Proportion table of review ratings.
prop.table(xtabs(~data$revs_rating))
```
We decide to take ratings greater than or equal to 98 to mean very high review scores. (Top 30%)

```{r}
densityPlot(data$revs_rating) # highly left skewed - most review scores are high
```

```{r}
#Creating new variable high_rating defining if observation has a very high review score
high_rating <- data$revs_rating
high_rating[data$revs_rating >= 98] <- 1
high_rating[data$revs_rating < 98] <- 0
data <- data %>% mutate(high_rating = high_rating)
data$high_rating <- as.numeric(data$high_rating)
```

Exploratory analysis - relationships with review score
```{r}
#Probability plots:
par(mfrow=c(3,4))
for(v in cvars){
  x <- xtabs( ~ data$high_rating + data[,v] )
  prob <- x[2,] / ( x[1,] + x[2,]) # sample probability of score>=98
  plot( sort( unique( data[,v] ) ), prob, pch=19,
      xlab=v, ylab="Probability of rating >= 98")
}

#Factor variables:
prop.table(xtabs( ~ high_rating + n_hood, data),2)
# Barra da Tijuca more likely to have high rating => include n_hood in models
```
Conclusions from plots:
* price seems to have some sort of relationship with high rating but not very obvious
* effect of price may be more of an interaction with # guests for instance
* higher response rate doesn't seem to increase rating - not v surprising since it measures % responses to enquiries about new bookings as opposed to enquiries during stay
* higher list count associated with smaller probability of high rating
* rating more likely to be high with large number of bathrooms - bit random lol
* no obvious relationship with min_nights, guests, reviews per month or availability
* wouldn't expect rating to depend solely on number of guests, bathrooms, location etc. since these factors have all been considered by guests before selecting the property

trends with bathrooms, accommodates, and list count

```{r}
#Continuous variables with rating:
par(mfrow=c(3,4))
for(v in cvars)plot(data[,v], data$revs_rating, xlab =v, ylab="Rev rating")

#Correlation with rating:
noNAs <- na.omit(data[,-c(4,5,6,15,16)]) 
cors <- round(cor(noNAs, use = "pairwise"),2)
cors[10,]
# highest correlations: price(+), response rate(-), # listings(-), reviews(+)
```

```{r}
#Making factor variable for price to allow for non-linear relationship with rating
data$fct_price <- cut(data$price, breaks = c(0,100,150,200,300,500,1000), 
                      labels = c("0-99","100-149","150-199","200-299","300-499",">500"), 
                      right = F)
summary(data$fct_price)
```

```{r}
#Variables to include in model: neighbourhood, price, response rate, # listings, number of reviews, guests, bathrooms. Other variables not included as contextually they would not affect review ratings.
rating_mod1 <- glm(high_rating ~ price + resp_rate + list_count + n_hood + num_reviews + guests + bathrooms + avail_30, data=data, family=binomial)
summary(rating_mod1)

#Checking linearity assumption
vars <- c("price","resp_rate","list_count","num_reviews","guests","bathrooms","avail_30")
par(mfrow=c(2,2))
for(v in vars){
  binnedplot( na.omit(data)[,v], residuals(rating_mod1, type="deviance"),
            nclass = 15, xlab=v)
}

par(mfrow=c(2,2))
for(v in vars){
  plot( predict(rating_mod1,type="link"), na.omit(data)[,v],
        pch=20, xlab=v)
}


#Step model
rating_step1 <- step(rating_mod1,trace=F)
summary(rating_step1)
par(mfrow=c(2,2))
for(v in vars){
  binnedplot( na.omit(data)[,v], residuals(rating_step1, type="deviance"),
            nclass = 15, xlab=v)
}

par(mfrow=c(2,2))
for(v in vars){
  plot( predict(rating_step1,type="link"), na.omit(data)[,v],
        pch=20, xlab=v)
}
```

```{r}
#Model with accommodates instead of guests
rating_mod2 <- glm(high_rating ~ price + accommodates + bathrooms + resp_rate + n_hood + list_count + num_reviews + avail_30, data=data, family=binomial)
summary(rating_mod2)

vars2 <- c("price","accommodates","bathrooms","resp_rate","list_count","num_reviews","avail_30")
par(mfrow=c(2,2))
for(v in vars2){
  binnedplot( na.omit(data)[,v], residuals(rating_mod2, type="deviance"),
            nclass = 15, xlab=v)
}

# step doesn't remove any variables

rating_mod3 <- update(rating_mod2, .~. + prop_type + room_type)
anova(rating_mod2,rating_mod3,test="LRT")
# property type and room type have no significant effect given other predictors
```

Summary:

* Price and guests do not appear to influence the probability of a high rating being awarded in the first model. This is not too surprising as these factors have already been considered by guests when choosing a property to stay in. 
* Number of bathrooms is highly significant 
* Interestingly, in model with guests but no bathrooms, price becomes highly significant but guests still insignificant. Using accommodates instead of guests causes all coefficients to become significant (higher accommodates decreases prob of high rating). Price in this model increases prob of high rating.
* High rating more likely in Barra da Tijuca compared to other 2 districts

Assumptions that need to be met:

* Independence of observations, i.e. whether or not a rating is high must be independent of other ratings. This is a reasonable assumption because the rating of one property should not depend on the rating of any others. *Would this still hold for private/shared rooms of the same property? (If not should we restrict the data to only entire homes/apts?)*
* Identically distributed
* Linear relationship with continuous variables - investigate by plotting binned residual plots or linear predictor against each explanatory variable 

```{r}
#Investigating interactions
int_test <- step(rating_mod2,scope=list(upper=~ price*accommodates*bathrooms*avail_30*n_hood*resp_rate*list_count*num_reviews,lower=~1),trace=F)
summary(int_test)

#Removes these 2 interactions as they did not make sense contexually.
rating_final <- update(int_test, .~. - accommodates:list_count - resp_rate:n_hood)
summary(rating_final)
```

```{r}
#Model diagnostics: binned continuous covariates against residuals
vars2 <- c("price","accommodates","bathrooms","resp_rate","list_count","num_reviews","avail_30")
par(mfrow=c(2,2))
for(v in vars2){
  binnedplot( na.omit(data)[,v], residuals(rating_final, type="deviance"),
            nclass = 15, xlab=v)
}
```
```{r}
par(mfrow=c(1,2))
#Binned residual plot
binnedplot( rating_final$fitted.values, residuals(rating_final, type="deviance"),
            nclass = 20, ylab="Average deviance residuals" )

#Predicted vs observed proportions plot
## Define the bins
num_bins <- 20
cut_offs <- quantile( rating_final$fitted.values, 
                      (0:num_bins) / num_bins )

## Compute observed and predicted proportions for each bin
proportion_observed  <- rep(0, num_bins)
proportion_predicted <- rep(0, num_bins) 

for( i in 1:num_bins ){
  ind <- which( rating_final$fitted.values >= cut_offs[i] & 
                rating_final$fitted.values <  cut_offs[i+1]  )
  proportion_observed[i]  <- mean( data$high_rating[ind] )
  proportion_predicted[i] <- mean( rating_final$fitted.values[ind] )
}

## Plot predicted against observed proportions
plot( proportion_predicted, proportion_observed, pch=20,
      xlab="Predicted Proportions", ylab="Observed Proportions",
      main="Plot of fitted vs observed probabilities \nof high rating",
      xlim=c(0,1),ylim=c(0,1))
abline(0,1,lty=2)

# predicted and observed proportions quite similar so fit not too bad
```

Sensitivity analysis: changing threshold of "high review"
```{r}
# High review = 100
data %>% mutate(high_rating100 = factor(ifelse(revs_rating < 100, 0, 1))) -> data
rating_100 <- glm(high_rating100 ~ price + accommodates + bathrooms + resp_rate + n_hood + list_count + num_reviews + avail_30 + resp_rate:list_count + resp_rate:num_reviews + price:n_hood, data=data, family=binomial)
summary(rating_100)

#Linearity assumption
par(mfrow=c(2,2))
for(v in vars2){
  binnedplot( na.omit(data)[,v], residuals(rating_100, type="deviance"),
            nclass = 15, xlab=v)
}
# no longer satisfied
par(mfrow=c(2,2))
for(v in vars2){
  plot( predict(rating_100,type="link"), na.omit(data)[,v],
        pch=20, xlab=v)
}

# High review >= 95

data %>% mutate(high_rating95 = factor(ifelse(revs_rating < 95, 0, 1))) -> data
rating_95 <- glm(high_rating95 ~ price + accommodates + bathrooms + resp_rate + n_hood + list_count + num_reviews + avail_30 + resp_rate:list_count + resp_rate:num_reviews + price:n_hood, data=data, family=binomial)
summary(rating_95)

# Linearity assumption
par(mfrow=c(2,2))
for(v in vars2){
  binnedplot( na.omit(data)[,v], residuals(rating_100, type="deviance"),
            nclass = 15, xlab=v)
}
```

High rating threshold = 100

* Linearity assumptions not satisfied as well
* Ipanema not significant at 5% level
* Magnitude and sign of other coefficients similar, except for num_reviews

High rating threshold: >=95

* Diagnostics better - more points lie within expected values
* All significant except num_reviews
* Bathrooms coeff much smaller, other coeffs similar magnitude

```{r}
summary(rating_final)

cbind(exp(coef(rating_final)),exp(confint(rating_final)))

#Effect of $50 increase in price
exp(coef(rating_final)[2]*100)

#Coefficient plot
ggcoef(rating_final, exclude_intercept = TRUE, shape = 18, color = "purple", exponentiate = TRUE)
```


